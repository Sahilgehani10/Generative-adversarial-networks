{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b8f199-6844-4696-8aec-23faf9bf2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2038b45e-d970-459e-af57-b82ad008dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00b8689-78d4-4c65-9041-8bc656833c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20fa093",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=tfds.load('fashion_mnist',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a8e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.as_numpy_iterator().next()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09db4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transformation\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf00a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiterator=ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd66b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad65586",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=4,figsize=(20,20))\n",
    "for idx in range(4):\n",
    "    batch=dataiterator.next()\n",
    "    ax[idx].imshow(np.squeeze(batch['image']))\n",
    "    ax[idx].title.set_text(batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b5f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_images(data):\n",
    "    image=data['image']\n",
    "    return image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9211c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=tfds.load('fashion_mnist',split='train')\n",
    "ds=ds.map(scale_images)\n",
    "ds=ds.cache()\n",
    "ds=ds.shuffle(60000)\n",
    "ds=ds.batch(128)\n",
    "ds=ds.prefetch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c6673",
   "metadata": {},
   "source": [
    "NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14aee4",
   "metadata": {},
   "source": [
    "build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe14f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Conv2D,Reshape,LeakyReLU,Dropout,UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ae807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Dense(7*7*128,input_dim=128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "\n",
    "    #upsampling block 1\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,5,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    #upsampling block 2\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,5,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Convolutional block 1\n",
    "    model.add(Conv2D(128,4,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Convolutional block 2\n",
    "    model.add(Conv2D(128,4,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Conv layer to get to one channel\n",
    "    model.add(Conv2D(1,4,padding='same',activation='sigmoid'))\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c406d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=build_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c47d6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d7e5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=generator.predict(np.random.randn(4,128,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c977c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d8fa9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=4,figsize=(20,20))\n",
    "for idx,img in enumerate(img):\n",
    "    ax[idx].imshow(np.squeeze(img))\n",
    "    ax[idx].title.set_text(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62442369",
   "metadata": {},
   "source": [
    "Build Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddc82c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model=Sequential()\n",
    "\n",
    "    #First conv block\n",
    "    model.add(Conv2D(32,5,input_shape=(28,28,1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #Second conv block\n",
    "    model.add(Conv2D(64,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #Third conv block\n",
    "    model.add(Conv2D(128,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #Fourth conv block\n",
    "    model.add(Conv2D(256,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fad9495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator=build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44c5856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76eaaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91909a79",
   "metadata": {},
   "source": [
    "Construct Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c642e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c044edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt=Adam(learning_rate=0.0001)\n",
    "d_opt=Adam(learning_rate=0.00001)\n",
    "g_loss=BinaryCrossentropy()\n",
    "d_loss=BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5724ce",
   "metadata": {},
   "source": [
    "Build subclassed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6130c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "146dd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.normal((6,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f76ad307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionGAN(Model):\n",
    "    def __init__(self,generator,discriminator,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "\n",
    "        self.generator=generator\n",
    "        self.discriminator=discriminator\n",
    "\n",
    "\n",
    "    def compile(self,g_opt,d_opt,g_loss,d_loss,*args,**kwargs):\n",
    "        super().compile(*args,**kwargs)\n",
    "        self.g_opt=g_opt\n",
    "        self.d_opt=d_opt\n",
    "        self.g_loss=g_loss\n",
    "        self.d_loss=d_loss\n",
    "    def train_step(self,batch):\n",
    "        real_images=batch\n",
    "        fake_images=self.generator(tf.random.normal((128,128,1)),training=False)\n",
    "\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            yhat_real=self.discriminator(real_images,training=True)\n",
    "            yhat_fake=self.discriminator(fake_images,training=True)\n",
    "            yhat_realfake=tf.concat([yhat_real,yhat_fake],axis=0)\n",
    "\n",
    "            y_realfake=tf.concat([tf.zeros_like(yhat_real),tf.ones_like(yhat_fake)],axis=0)\n",
    "\n",
    "            noise_real=0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake=-0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake+=tf.concat([noise_real,noise_fake],axis=0)  \n",
    "\n",
    "            total_d_loss=self.d_loss(y_realfake,yhat_realfake)\n",
    "\n",
    "        dgrad=d_tape.gradient(total_d_loss,self.discriminator.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(dgrad,self.discriminator.trainable_variables))\n",
    "        \n",
    "        with tf.GradientTape() as g_tape:\n",
    "            gen_images=self.generator(tf.random.normal((128,128,1)),training=True)\n",
    "            predicted_labels=self.discriminator(gen_images,training=False)\n",
    "            total_g_loss=self.g_loss(tf.zeros_like(predicted_labels),predicted_labels)\n",
    "        ggrad=g_tape.gradient(total_g_loss,self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad,self.generator.trainable_variables))\n",
    "        return {'d_loss':total_d_loss,'g_loss':total_g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c36329bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashgan=FashionGAN(generator,discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c6f6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashgan.compile(g_opt,d_opt,g_loss,d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af345418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51ee8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=fashgan.fit(ds,epochs=20,callbacks=[ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6033369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['d_loss'], label='d_loss')\n",
    "plt.plot(hist.history['g_loss'], label='g_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61449b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(os.path.join('archive', 'generatormodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = generator.predict(tf.random.normal((16, 128, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74075599",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))\n",
    "for r in range(4): \n",
    "    for c in range(4): \n",
    "        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506dcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
